{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        This method is used to fit the classifier to the training data. It initializes the \n",
    "        number of samples, number of features and number of classes using the input data.\n",
    "        It also creates three zero-matrices to store summary statistics and prior probabilities.\n",
    "        \"\"\"\n",
    "        # get number of samples (rows) and features (columns)\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "\n",
    "        # get number of uniques classes\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        \n",
    "        # create three zero-matrices to store summary stats & prior\n",
    "        self.mean = np.zeros((self.n_classes, self.n_features))\n",
    "        self.variance = np.zeros((self.n_classes, self.n_features))\n",
    "        self.priors = np.zeros(self.n_classes)\n",
    "\n",
    "        for c in range(self.n_classes):\n",
    "            # create a subset of data for the specific class 'c'\n",
    "            X_c = X[y == c]\n",
    "            \n",
    "            # calculate statistics and update zero-matrices, rows=classes, cols=features\n",
    "            self.mean[c, :] = np.mean(X_c, axis=0)\n",
    "            self.variance[c, :] = np.var(X_c, axis=0)\n",
    "            self.priors[c] = X_c.shape[0] / self.n_samples\n",
    "\n",
    "    def gaussian_density(self, x, mean, var):\n",
    "        \"\"\"\n",
    "        This method calculates the gaussian density function for a given sample, mean and variance.\n",
    "        \"\"\"\n",
    "        const = 1 / np.sqrt(var * 2 * np.pi)\n",
    "        proba = np.exp(-0.5 * ((x - mean) ** 2 / var))\n",
    "        return const * proba\n",
    "\n",
    "    \n",
    "    def get_class_probability(self, x):\n",
    "        \"\"\"\n",
    "        This method calculates the class probability for a given sample using the Gaussian density function.\n",
    "        \"\"\"\n",
    "        # store new posteriors for each class in a single list\n",
    "        posteriors = list()\n",
    "\n",
    "        for c in range(self.n_classes):\n",
    "            # get summary stats & prior\n",
    "            mean = self.mean[c]\n",
    "            variance = self.variance[c]\n",
    "            prior = np.log(self.priors[c])\n",
    "            \n",
    "            # calculate new posterior & append to list\n",
    "            posterior = np.sum(np.log(self.gaussian_density(x, mean, variance)))\n",
    "            posterior = prior + posterior\n",
    "            posteriors.append(posterior)\n",
    "        \n",
    "        # return the index with the highest class probability\n",
    "        return np.argmax(posteriors)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        # for each sample x in the dataset X\n",
    "        y_hat = [self.get_class_probability(x) for x in X]\n",
    "        return np.array(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and adjust labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_df = pd.read_csv('analysis/feature_list.csv')\n",
    "\n",
    "beer_df.loc[beer_df['Label'] == 'open_broken', 'Label'] = 0\n",
    "beer_df.loc[beer_df['Label'] == 'broken', 'Label'] = 1\n",
    "beer_df.loc[beer_df['Label'] == 'closed_sealed', 'Label'] = 2\n",
    "beer_df.loc[beer_df['Label'] == 'closed_seal_broken', 'Label'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide the dataset in data columns and one label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all but the last column\n",
    "data = beer_df.iloc[:,:-1]\n",
    "#convert all cells from str to float, neccessary because of str type labels\n",
    "data = data.astype(float)\n",
    "# take just the last column that contains labels\n",
    "label = beer_df.iloc[:,-1]\n",
    "#convert to np array\n",
    "data = np.asarray(data)\n",
    "label = np.asarray(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate, train and predict Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes()\n",
    "nb.fit(X_train, y_train)\n",
    "predictions = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Bayes 0.6287878787878788 \n",
      "\n",
      "**********************************\n",
      "\n",
      "[[67  0  1  2]\n",
      " [ 8  3 45  8]\n",
      " [ 7  3 42 10]\n",
      " [ 4  1  9 54]] \n",
      "\n",
      "**********************************\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            broken       0.78      0.96      0.86        70\n",
      "closed_seal_broken       0.43      0.05      0.08        64\n",
      "     closed_sealed       0.43      0.68      0.53        62\n",
      "       open_broken       0.73      0.79      0.76        68\n",
      "\n",
      "          accuracy                           0.63       264\n",
      "         macro avg       0.59      0.62      0.56       264\n",
      "      weighted avg       0.60      0.63      0.57       264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_accuracy(y_true, y_hat):\n",
    "     return np.sum(y_true==y_hat) / len(y_true)\n",
    "\n",
    "Y_pred = nb.predict(X_test)\n",
    "\n",
    "\n",
    "Y_pred = np.where(Y_pred == 0, 'open_broken',\n",
    "                 np.where(Y_pred == 1, 'broken',\n",
    "                 np.where(Y_pred == 2, 'closed_sealed',\n",
    "                 np.where(Y_pred == 3, 'closed_seal_broken', Y_pred))))\n",
    "\n",
    "Y_pred = Y_pred.astype(np.str_)\n",
    "\n",
    "y_test = np.where(y_test == 0, 'open_broken',\n",
    "                 np.where(y_test == 1, 'broken',\n",
    "                 np.where(y_test == 2, 'closed_sealed',\n",
    "                 np.where(y_test == 3, 'closed_seal_broken', y_test))))\n",
    "\n",
    "y_test = np.array([np.array(x) for x in y_test])\n",
    "y_test = y_test.astype(np.ndarray)\n",
    "y_test = np.array(y_test, dtype=np.ndarray)\n",
    "\n",
    "#  Fast output of the classifier's accuracy\n",
    "print('Accuracy Bayes',accuracy_score(y_test, Y_pred),'\\n')\n",
    "print('**********************************\\n')\n",
    "\n",
    "\n",
    "#***************************************************************\n",
    "# Showing of the confusion matrix\n",
    "# Predicting the classes with the test data set\n",
    "print(confusion_matrix(y_test, Y_pred),'\\n')\n",
    "print('**********************************\\n')\n",
    "\n",
    "#***************************************************************\n",
    "# Showing the classification report\n",
    "print(classification_report(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Bayes: 0.6287878787878788 \n",
      "\n",
      "**********************************\n",
      "\n",
      "[[67  0  1  2]\n",
      " [ 8  3 45  8]\n",
      " [ 7  3 42 10]\n",
      " [ 4  1  9 54]] \n",
      "\n",
      "**********************************\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            broken       0.78      0.96      0.86        70\n",
      "closed_seal_broken       0.43      0.05      0.08        64\n",
      "     closed_sealed       0.43      0.68      0.53        62\n",
      "       open_broken       0.73      0.79      0.76        68\n",
      "\n",
      "          accuracy                           0.63       264\n",
      "         macro avg       0.59      0.62      0.56       264\n",
      "      weighted avg       0.60      0.63      0.57       264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trainieren des Bayes Klassifikators \n",
    "from sklearn.naive_bayes import GaussianNB # importiere Bayes-Klassifikator\n",
    "df = pd.read_csv('analysis/feature_list.csv')\n",
    "\n",
    "# alles au√üer die letzte Spalte\n",
    "X = df.iloc[:,:-1]\n",
    "# nur die letzte Spalte  \n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,\n",
    "                                                   random_state=42)\n",
    "\n",
    "bayes_clf = GaussianNB()\n",
    "\n",
    "\n",
    "bayes_clf.fit(X_train,y_train) # fit classifier on data\n",
    "\n",
    "#  Fast output of the classifier's accuracy\n",
    "print('Accuracy Bayes:',bayes_clf.score(X_test,y_test),'\\n')\n",
    "print('**********************************\\n')\n",
    "\n",
    "#***************************************************************\n",
    "# Showing of the confusion matrix\n",
    "# Predicting the classes with the test data set\n",
    "y_pred = bayes_clf.predict(X_test) #take test data as prediction data\n",
    "print(confusion_matrix(y_test, y_pred),'\\n')\n",
    "print('**********************************\\n')\n",
    "\n",
    "#***************************************************************\n",
    "# Showing the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
